# Get Started with AI on AMD Platforms

AMD is uniquely position to run AI models in the breath of its technology.

In this page, we will focus on AI inference on the different AMD technologies.
We will show you how to run pre-trained models from popular model hubs such as
HuggingFace, PyTorch Hub, etc. In the getting started we will mostly focus on
the model functionality and how to run it on AMD technologies, model architecture
and deeper understanding of the model internals will be covered in a different
section.

PyTorch is our framework of choice for most of these resources due to its huge
popularity, however, you will be able to find similar examples in any of the
other popular AI frameworks.

## Requisites

```{card}
CPUs: {bdg-primary}`AMD EPYC™ Processors` {bdg-primary}`AMD Ryzen™ Processors` {bdg-primary}`AMD Ryzen™ AI Processors`

Or

GPUs: {bdg-primary}`AMD Instinct™ Accelerators` {bdg-primary}`AMD Radeon™ RX Graphics Cards` {bdg-primary}`AMD Radeon™ PRO Graphics Cards`
```

- [Setup environment](env/env.md)

## Run Pre-trained Models

We provide a number of notebooks where you can run pre-trained models.

At the top of the notebook we will provide a tag of the technologies where the
notebook can be run on using the following colors.

```{card}
{bdg-primary}`Direct support` {bdg-secondary}`Can run on systems with enough memory`
```

Check out:

```{tableofcontents}
```

## More Resources

List of extra resources listed in no particular order.

- [Microsoft Resnet-18 from Hugging Face](https://huggingface.co/microsoft/resnet-18)
- [Image classification using Vision Transformer with AMD GPUs](https://rocm.blogs.amd.com/artificial-intelligence/vit-inference/README.html)
- [Efficient image generation with Stable Diffusion models and ONNX Runtime using AMD GPUs](https://rocm.blogs.amd.com/artificial-intelligence/stable-diffusion-onnx-runtime/README.html)
- [Segment Anything with AMD GPUs](https://rocm.blogs.amd.com/artificial-intelligence/segment-anything/README.html)
- [text-generation-webui](https://github.com/oobabooga/text-generation-webui)
- [AUTOMATIC1111 stable-diffusion-webui](https://github.com/AUTOMATIC1111/stable-diffusion-webui)
- [How to run a Large Language Model (LLM) on your AMD Ryzen™ AI PC or Radeon™ Graphics Card](https://community.amd.com/t5/ai/how-to-run-a-large-language-model-llm-on-your-amd-ryzen-ai-pc-or/ba-p/670709)
- [Experience Meta Llama 3 with AMD Ryzen™ AI and Radeon™ 7000 Series Graphics](https://community.amd.com/t5/ai/experience-meta-llama-3-with-amd-ryzen-ai-and-radeon-7000-series/ba-p/680061)
- [Automatic1111 Stable Diffusion WebUI with DirectML Extension on AMD GPUs](https://community.amd.com/t5/ai/how-to-automatic1111-stable-diffusion-webui-with-directml/ba-p/649027)
- [Developer Blog: Build a Chatbot with Ryzen™ AI Processors](https://community.amd.com/t5/ai/developer-blog-build-a-chatbot-with-ryzen-ai-processors/ba-p/680693)
- [DBRX Instruct on AMD GPUs](https://rocm.blogs.amd.com/artificial-intelligence/dbrx/README.html)
- [Deep Learning Recommendation Models on AMD GPUs](https://rocm.blogs.amd.com/artificial-intelligence/dlrm/README.html)
- [LM Studio](https://lmstudio.ai/)
- [Llamafile](https://github.com/Mozilla-Ocho/llamafile)
- [Ollama](https://www.ollama.com/)

----------
Copyright (C) 2025 Advanced Micro Devices, Inc. All rights reserved.

SPDX-License-Identifier: MIT