{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Classification with an MLP Hugging Face Model\n",
    "\n",
    "This notebook shows you how to run a pretrained model hosted on Hugging Face. https://huggingface.co/dacorvo/mnist-mlp\n",
    "\n",
    "## üõ†Ô∏è Supported Hardware\n",
    "\n",
    "This notebook can run in a CPU or in a GPU.\n",
    "\n",
    "‚úÖ AMD Instinct‚Ñ¢ Accelerators  \n",
    "‚úÖ AMD Radeon‚Ñ¢ RX/PRO Graphics Cards  \n",
    "‚úÖ AMD EPYC‚Ñ¢ Processors  \n",
    "‚úÖ AMD Ryzen‚Ñ¢ (AI) Processors  \n",
    "\n",
    "Suggested hardware: **AI PC powered by AMD Ryzen‚Ñ¢ AI Processors**\n",
    "\n",
    "## ‚ö° Recommended Software Environment\n",
    "\n",
    "::::{tab-set}\n",
    "\n",
    ":::{tab-item} Linux\n",
    "- [Install Docker container](https://amdresearch.github.io/aup-ai-tutorials//env/env-gpu.html)\n",
    "- [Install PyTorch](https://amdresearch.github.io/aup-ai-tutorials//env/env-cpu.html)\n",
    ":::\n",
    "\n",
    ":::{tab-item} Windows\n",
    "- [Install Direct-ML](https://amdresearch.github.io/aup-ai-tutorials//env/env-gpu-windows.html)\n",
    "- [Install PyTorch](https://amdresearch.github.io/aup-ai-tutorials//env/env-cpu.html)\n",
    ":::\n",
    "::::\n",
    "\n",
    "## üéØ Goals\n",
    "\n",
    "- Show you how to download a model from HuggingFace\n",
    "- Run MNIST on an AMD platform\n",
    "- Explore the MNIST dataset and run inference of one of the test examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Run MNIST on an AMD Platform\n",
    "\n",
    "Import packages, in particular [Hugging Face `transformers`](https://huggingface.co/docs/transformers/en/index) that helps downloading the model from the Hugging Face repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the model from Hugging Face using `transformers.AutoModel` by specifying address. See more information on how to download models [here](https://huggingface.co/docs/hub/en/models-downloading)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "model = AutoModel.from_pretrained(\"dacorvo/mnist-mlp\", trust_remote_code=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the model layers, as you can see, this is a very simple model with 3 layers.\n",
    "\n",
    "| Layer name | Input Features | Output Features |\n",
    "|------------|----------------|-----------------|\n",
    "| Input      |     784        |      256        |\n",
    "| Middle     |     256        |      256        |\n",
    "| Output     |     256        |       10        | "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (input_layer): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (mid_layer): Linear(in_features=256, out_features=256, bias=True)\n",
      "  (output_layer): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download MNIST dataset and apply a normalization transformation as well as flattening the dimensions. As you can see, we do not download the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,)),\n",
    "        transforms.Lambda(lambda x: torch.flatten(x)),\n",
    "])\n",
    "\n",
    "test_set = datasets.MNIST('datasets/', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a random number to index a sample from the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random index=5760 with label=3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/py_3.12/lib/python3.12/site-packages/torchvision/datasets/mnist.py:81: UserWarning: test_data has been renamed data\n",
      "  warnings.warn(\"test_data has been renamed data\")\n"
     ]
    }
   ],
   "source": [
    "index = int(torch.randint(low=0, high=test_set.test_data.shape[0], size=(1,)))\n",
    "data, label = test_set[index]\n",
    "print(f'Random {index=} with {label=}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the hand-written digit that we have randomly selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure\n",
    "plt.imshow(data.reshape(28,28), cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title(f'Label: {int(label)}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can run an inference with the sample data on the model.\n",
    "\n",
    "```{note}\n",
    "We run the inference inside of the `torch.no_grad()` context in order not to track gradients. This saves memory and computation.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.6064e-12, 5.5341e-13, 1.1835e-07, 1.0000e+00, 1.8841e-17, 7.7729e-09,\n",
       "        4.6632e-18, 2.2053e-12, 6.5412e-11, 8.4408e-15])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    output = model(data)\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the model has ten output neurons, we are going to use `torch.argmax` to get the index of the neuron with the highest probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = torch.argmax(output)\n",
    "predicted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now check if the class we got after inference is the correct one. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is the prediction correct? True\n"
     ]
    }
   ],
   "source": [
    "print(f'Is the prediction correct? {predicted == label}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the accuracy of the downloaded model by checking the complete test set.\n",
    "We first create a `DataLoader` object that we will use to iterate over the test images. Using this object we loop over the images and labels, we use images to run the batched inference, then using the output we compute the predicted class and compare them with the actual class to compute the total number of correct predictions. After this, we can print the test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy:  96.57%\n"
     ]
    }
   ],
   "source": [
    "test_loader = DataLoader(test_set, batch_size=64, shuffle=False)\n",
    "correct_classifications = 0\n",
    "for images, labels in test_loader:\n",
    "    with torch.no_grad():\n",
    "        output = model(images)\n",
    "    correct_classifications += torch.sum(torch.argmax(output, dim=1) == labels).item()\n",
    "\n",
    "print(f'Test accuracy: {100*correct_classifications/len(test_set): .2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------\n",
    "Copyright (C) 2025 Advanced Micro Devices, Inc. All rights reserved.\n",
    "\n",
    "SPDX-License-Identifier: MIT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
