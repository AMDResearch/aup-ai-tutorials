{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4bf57ae8-810c-41bd-8a9d-f6e03ad21890",
   "metadata": {},
   "source": [
    "# OpenAI Whisper - Speech Recognition\n",
    "\n",
    "Whisper is an automatic speech recognition (ASR) and speech translation pre-trained model. We are going to use Whisper for audio transcription.\n",
    "\n",
    "## üõ†Ô∏è Supported Hardware\n",
    "\n",
    "This notebook can run in a CPU or in a GPU.\n",
    "\n",
    "‚úÖ AMD Instinct‚Ñ¢ Accelerators  \n",
    "‚úÖ AMD Radeon‚Ñ¢ RX/PRO Graphics Cards  \n",
    "‚úÖ AMD EPYC‚Ñ¢ Processors  \n",
    "‚úÖ AMD Ryzen‚Ñ¢ (AI) Processors  \n",
    "\n",
    "Suggested hardware: **AI PC powered by AMD Ryzen‚Ñ¢ AI Processors**\n",
    "\n",
    "## ‚ö° Recommended Software Environment\n",
    "\n",
    "::::{tab-set}\n",
    "\n",
    ":::{tab-item} Linux\n",
    "- [Install Docker container](https://amdresearch.github.io/aup-ai-tutorials//env/env-gpu.html)\n",
    "- [Install PyTorch](https://amdresearch.github.io/aup-ai-tutorials//env/env-cpu.html)\n",
    ":::\n",
    "\n",
    ":::{tab-item} Windows\n",
    "- [Install Direct-ML](https://amdresearch.github.io/aup-ai-tutorials//env/env-gpu-windows.html)\n",
    "- [Install PyTorch](https://amdresearch.github.io/aup-ai-tutorials//env/env-cpu.html)\n",
    ":::\n",
    "::::\n",
    "\n",
    "## üéØ Goals\n",
    "\n",
    "- Show you how to download a model from HuggingFace\n",
    "- Run OpenAI Whisper on an AMD platform\n",
    "- Get OpenAI Whisper to transcribe an audio file\n",
    "\n",
    ":::{seealso}\n",
    "- [Whisper](https://huggingface.co/openai/whisper-small)\n",
    "- [Robust Speech Recognition via Large-Scale Weak Supervision](https://arxiv.org/abs/2212.04356)\n",
    "- [Whisper GitHub](https://github.com/openai/whisper)\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eea4968",
   "metadata": {},
   "source": [
    "## üöÄ Run OpenAI Whisper on an AMD Platform\n",
    "\n",
    "Import the necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0149b8d2-ed73-423a-bb77-4d101f681e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "from datasets import load_dataset\n",
    "from IPython.display import Audio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9487e2e0",
   "metadata": {},
   "source": [
    "Load the model from Hugging Face and processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1124a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
    "model = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")\n",
    "model.config.forced_decoder_ids = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15920a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Model size: {model.num_parameters() * model.dtype.itemsize / 1024 / 1024:.2f} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3073c4b1",
   "metadata": {},
   "source": [
    "Let's load a test audio file\n",
    "\n",
    ":::{note} Dataset Download Disclaimer\n",
    "\n",
    "By executing the next cell, you will initiate the download of the dataset `hf-internal-testing/librispeech_asr_dummy‚Äô. Please note that this dataset may include content subject to third-party ownership or licensing restrictions. By proceeding, you acknowledge and agree to the following:\n",
    "- You are solely responsible for reviewing and complying with any applicable terms of use, licenses, or permissions required by the dataset owner.\n",
    "- If explicit permission is required from the original owner or provider, you must obtain that permission before using the dataset for any purpose, including research, analysis, or redistribution.\n",
    "- AMD Inc. is not distributing the dataset and is providing a link solely for your convenience. AMD Inc.  does not grant any rights to the dataset and disclaims all liability for misuse or unauthorized access.\n",
    "If you are uncertain about the licensing or permission requirements, please consult the dataset documentation or contact the dataset owner directly.\n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd5b3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "sample = ds[0][\"audio\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db0e375",
   "metadata": {},
   "source": [
    "We are going to use the `processor` to generate the input features that we will feed to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d8e108",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = processor(sample[\"array\"], sampling_rate=sample[\"sampling_rate\"], return_tensors=\"pt\").input_features\n",
    "print(input_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fe678e",
   "metadata": {},
   "source": [
    "Let's get the model to generate the output tokens that we can then decode with the `processor` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d195bcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ids = model.generate(input_features)\n",
    "transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379d85d7",
   "metadata": {},
   "source": [
    "Compare the transcript with the actual audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413a1080",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transcription)\n",
    "Audio(data=sample['array'], rate=sample['sampling_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbc31f3",
   "metadata": {},
   "source": [
    "Let's try with a different audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b942bef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = ds[9][\"audio\"]\n",
    "input_features = processor(sample[\"array\"], sampling_rate=sample[\"sampling_rate\"], return_tensors=\"pt\").input_features \n",
    "\n",
    "predicted_ids = model.generate(input_features)\n",
    "transcription = processor.batch_decode(predicted_ids, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edc719b",
   "metadata": {},
   "source": [
    "Compare the transcript with the actual audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08775d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(transcription)\n",
    "Audio(data=sample['array'], rate=sample['sampling_rate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f79d8f",
   "metadata": {},
   "source": [
    "----------\n",
    "Copyright (C) 2025 Advanced Micro Devices, Inc. All rights reserved.\n",
    "\n",
    "SPDX-License-Identifier: MIT"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
